# MCTS-LLM Alpha Mining Framework Wiki

Welcome to the MCTS-LLM Alpha Mining Framework wiki! This wiki provides comprehensive documentation for developers and researchers.

## ðŸ“š Documentation Structure

### Getting Started
- [Installation Guide](Installation-Guide)
- [Quick Start Tutorial](Quick-Start-Tutorial)
- [Configuration Guide](Configuration-Guide)

### Core Concepts
- [MCTS Algorithm Overview](MCTS-Algorithm)
- [Alpha Factor Basics](Alpha-Factor-Basics)
- [Multi-dimensional Evaluation](Evaluation-System)

### Advanced Topics
- [Formula Language Reference](Formula-Language)
- [LLM Integration Details](LLM-Integration)
- [Performance Optimization](Performance-Optimization)

### Development
- [Contributing Guidelines](Contributing)
- [Architecture Deep Dive](Architecture)
- [API Reference](API-Reference)

### Troubleshooting
- [Common Issues](Common-Issues)
- [FAQ](FAQ)
- [Debug Guide](Debug-Guide)

## ðŸ”— Quick Links

- [GitHub Repository](https://github.com/dtbtc/mcts-llm-alpha)
- [Issue Tracker](https://github.com/dtbtc/mcts-llm-alpha/issues)
- [Releases](https://github.com/dtbtc/mcts-llm-alpha/releases)

## ðŸ“Š System Overview

The MCTS-LLM Alpha Mining Framework combines:
1. **Monte Carlo Tree Search** for systematic exploration
2. **Large Language Models** for creative formula generation
3. **Multi-dimensional Evaluation** for comprehensive quality assessment
4. **Real Market Data** via Qlib integration

## ðŸŽ¯ Key Features

- Two-step generation: Portrait â†’ Formula
- Virtual action mechanism for internal node expansion
- Relative ranking with dynamic scoring
- Few-shot learning for context-aware refinement
- Comprehensive caching for performance

## ðŸ“ˆ Recent Updates

- **v1.0.0** - Initial release with full paper implementation
- Fixed relative ranking mechanism
- Enhanced parameter optimization
- Improved cold-start handling

---

For questions or contributions, please check our [Contributing Guidelines](Contributing) or open an [issue](https://github.com/dtbtc/mcts-llm-alpha/issues).