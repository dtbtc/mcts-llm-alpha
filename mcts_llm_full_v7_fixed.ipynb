{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM + MCTS 公式化 Alpha 挖掘 · v7修正版\n",
    "\n",
    "版本 v7-fixed – 修复了refinement逻辑，实现基于论文的两步生成过程\n",
    "\n",
    "## 主要改进\n",
    "1. 实现了基于论文的两步生成：先生成Alpha Portrait，再生成具体公式\n",
    "2. 修复了refinement逻辑，确保每次生成不同的改进公式\n",
    "3. 为每个维度提供特定的改进提示\n",
    "4. 添加了refinement历史追踪\n",
    "5. 实现了few-shot示例选择机制\n",
    "6. 修复了多个算子兼容性问题（Pct, Vari, Autocorr, Zscore等）\n",
    "7. 改进了窗口参数处理逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import qlib\n",
    "from qlib.data import D\n",
    "from openai import OpenAI\n",
    "import warnings\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 全局变量，在main函数中初始化\n",
    "client = None\n",
    "close_df = None\n",
    "returns_df = None\n",
    "start_date, end_date = \"2020-01-01\", \"2024-12-31\"\n",
    "universe = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCTS 树结构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNode:\n",
    "    def __init__(self, formula, parent=None, action_dim=None, complexity_budget=3):\n",
    "        self.formula = formula\n",
    "        self.parent = parent\n",
    "        self.action_dim = action_dim  # 从父节点通过哪个维度扩展而来\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.value = 0.0\n",
    "        self.scores = None\n",
    "        self.factor_returns = None\n",
    "        self.complexity_budget = complexity_budget\n",
    "        self.effective_count = 0  # 有效alpha数量\n",
    "        self.is_terminal = False\n",
    "        self.expansions_per_dim = {d: 0 for d in [\"Effectiveness\", \"Stability\", \"Turnover\", \"Diversity\", \"Overfitting\"]}\n",
    "        self.refinement_history = []  # 记录refinement历史\n",
    "        self.alpha_portrait = None  # 记录Alpha Portrait\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "    \n",
    "    def is_expandable(self):\n",
    "        # 检查是否还有维度可以扩展\n",
    "        expandable = any(count < 2 for count in self.expansions_per_dim.values()) and not self.is_terminal\n",
    "        # 如果节点已经尝试了足够多次但分数仍然很低，标记为终端节点\n",
    "        if self.visits > 5 and self.value / max(self.visits, 1) < 3.0:\n",
    "            self.is_terminal = True\n",
    "            expandable = False\n",
    "        return expandable\n",
    "    \n",
    "    def uct_value(self, c=1.0):\n",
    "        if self.visits == 0:\n",
    "            return float('inf')\n",
    "        exploitation = self.value / self.visits\n",
    "        exploration = c * math.sqrt(2 * math.log(self.parent.visits) / self.visits)\n",
    "        return exploitation + exploration\n",
    "    \n",
    "    def best_child(self, c=1.0):\n",
    "        \"\"\"选择UCT值最高的子节点\"\"\"\n",
    "        return max(self.children, key=lambda n: n.uct_value(c))\n",
    "    \n",
    "    def expand(self, dimension, new_formula, scores, factor_returns, portrait=None, refinement_desc=None):\n",
    "        \"\"\"在指定维度上扩展新节点\"\"\"\n",
    "        # 动态预算管理：每个有效alpha增加1个预算\n",
    "        new_budget = self.complexity_budget\n",
    "        if scores and np.mean(list(scores.values())) >= 5.0:  # 有效性阈值\n",
    "            new_budget = self.complexity_budget + 1\n",
    "            \n",
    "        child = MCTSNode(new_formula, parent=self, action_dim=dimension, \n",
    "                        complexity_budget=new_budget)\n",
    "        child.scores = scores\n",
    "        child.factor_returns = factor_returns\n",
    "        child.effective_count = self.effective_count + (1 if scores else 0)\n",
    "        child.alpha_portrait = portrait\n",
    "        \n",
    "        # 继承并更新refinement历史\n",
    "        child.refinement_history = self.refinement_history.copy()\n",
    "        if refinement_desc:\n",
    "            child.refinement_history.append({\n",
    "                'dimension': dimension,\n",
    "                'description': refinement_desc,\n",
    "                'score_change': self._calculate_score_change(scores) if self.scores else None\n",
    "            })\n",
    "        \n",
    "        self.children.append(child)\n",
    "        self.expansions_per_dim[dimension] += 1\n",
    "        return child\n",
    "    \n",
    "    def _calculate_score_change(self, new_scores):\n",
    "        \"\"\"计算分数变化\"\"\"\n",
    "        if not self.scores or not new_scores:\n",
    "            return None\n",
    "        return {dim: new_scores.get(dim, 0) - self.scores.get(dim, 0) \n",
    "                for dim in self.scores.keys()}\n",
    "    \n",
    "    def backpropagate(self, value):\n",
    "        \"\"\"反向传播更新节点统计信息\"\"\"\n",
    "        self.visits += 1\n",
    "        self.value += value\n",
    "        if self.parent:\n",
    "            self.parent.backpropagate(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 公式清理和参数修复函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATEX_RE = re.compile(r\"(\\\\\\[|\\\\\\]|\\$)\")\n",
    "\n",
    "def sanitize_formula(expr: str) -> str:\n",
    "    \"\"\"去除 GPT 生成中的 LaTeX/Markdown 包裹和多余空白\"\"\"\n",
    "    original_expr = expr  # 保存原始输入用于调试\n",
    "    \n",
    "    # 去除常见的前缀和后缀\n",
    "    expr = expr.strip().strip('`').strip()\n",
    "    \n",
    "    # 去除代码块标记\n",
    "    if expr.startswith('```'):\n",
    "        lines = expr.split('\\n')\n",
    "        expr = '\\n'.join([line for line in lines if not line.startswith('```')])\n",
    "    \n",
    "    # 去除常见的赋值语句前缀\n",
    "    prefixes_to_remove = [\n",
    "        'alpha_factor = ',\n",
    "        'alpha = ',\n",
    "        'factor = ',\n",
    "        'plaintext',\n",
    "        'plain text',\n",
    "        'python',\n",
    "        'formula:',\n",
    "        'Formula:',\n",
    "        'expression:',\n",
    "        'Expression:',\n",
    "        'json',\n",
    "        'JSON'\n",
    "    ]\n",
    "    for prefix in prefixes_to_remove:\n",
    "        if expr.startswith(prefix):\n",
    "            expr = expr[len(prefix):].strip()\n",
    "    \n",
    "    # 检查是否是JSON字符串\n",
    "    if expr.startswith('{') and '\"formula\"' in expr:\n",
    "        # 这是完整的JSON响应，不应该作为公式\n",
    "        print(f\"警告：收到JSON响应而非公式: {expr[:100]}...\")\n",
    "        return \"\"\n",
    "    \n",
    "    # 去除LaTeX符号\n",
    "    expr = LATEX_RE.sub('', expr)\n",
    "    \n",
    "    # 使用负向前瞻，只在字段前没有$时才添加$\n",
    "    # 这样可以避免把已经有$的字段再加一次$\n",
    "    pattern = r'(?<!\\$)\\b(close|open|high|low|volume|vwap)\\b'\n",
    "    expr = re.sub(pattern, r'$\\1', expr, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 修复可能已经存在的双美元符号（降级处理）\n",
    "    expr = re.sub(r'\\$\\$(close|open|high|low|volume|vwap)\\b', r'$\\1', expr, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 去除多余的空白和换行\n",
    "    expr = expr.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    expr = ' '.join(expr.split())\n",
    "    \n",
    "    # 去除Python比较运算符（Qlib不支持）\n",
    "    # 如果包含比较运算符，尝试简化公式\n",
    "    if '<' in expr or '>' in expr or '==' in expr:\n",
    "        # 提取比较运算符之前的部分作为主公式\n",
    "        expr = re.split(r'[<>=]=?', expr)[0].strip()\n",
    "        # 如果提取后为空或太短，返回一个默认简单公式\n",
    "        if len(expr) < 10:\n",
    "            expr = \"Rank(Delta($close, 1) / Std($close, 10), 5)\"\n",
    "    \n",
    "    # 去除可能的常数项（如1e-6）如果它们不在括号内\n",
    "    expr = re.sub(r'\\s*\\+\\s*1e-\\d+\\s*(?![^()]*\\))', '', expr)\n",
    "    \n",
    "    return expr.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_params(expr):\n",
    "    \"\"\"修复缺失的参数\"\"\"\n",
    "    # 先修复操作符名称（GPT可能生成错误的名称）\n",
    "    # 移动平均类\n",
    "    expr = expr.replace('Ma(', 'Mean(')  # Ma -> Mean\n",
    "    expr = expr.replace('MA(', 'Mean(')  # MA -> Mean\n",
    "    expr = expr.replace('SMA(', 'Mean(') # SMA -> Mean\n",
    "    expr = expr.replace('SMean(', 'Mean(') # SMean -> Mean\n",
    "    expr = expr.replace('EMA(', 'Mean(') # EMA -> Mean (简化处理)\n",
    "    expr = expr.replace('WMA(', 'Mean(')  # WMA -> Mean\n",
    "    expr = expr.replace('Wma(', 'Mean(')  # Wma -> Mean\n",
    "    expr = expr.replace('EWMA(', 'Mean(') # EWMA -> Mean\n",
    "    expr = expr.replace('Ewma(', 'Mean(') # Ewma -> Mean\n",
    "    expr = expr.replace('mavg(', 'Mean(') # mavg -> Mean\n",
    "    expr = expr.replace('MAVG(', 'Mean(') # MAVG -> Mean\n",
    "    expr = expr.replace('Moving_Average(', 'Mean(')  # Moving_Average -> Mean\n",
    "    expr = expr.replace('MovingAverage(', 'Mean(')   # MovingAverage -> Mean\n",
    "    expr = expr.replace('moving_average(', 'Mean(')  # moving_average -> Mean\n",
    "    \n",
    "    # 基础函数名修正\n",
    "    expr = expr.replace('log(', 'Log(')  # log -> Log\n",
    "    expr = expr.replace('abs(', 'Abs(')  # abs -> Abs\n",
    "    expr = expr.replace('sqrt(', '**0.5')  # sqrt用幂运算替代\n",
    "    expr = expr.replace('mean(', 'Mean(')  # mean -> Mean\n",
    "    expr = expr.replace('std(', 'Std(')   # std -> Std\n",
    "    expr = expr.replace('sum(', 'Sum(')   # sum -> Sum\n",
    "    expr = expr.replace('corr(', 'Corr(') # corr -> Corr\n",
    "    expr = expr.replace('rank(', 'Rank(') # rank -> Rank\n",
    "    expr = expr.replace('min(', 'Min(')   # min -> Min\n",
    "    expr = expr.replace('max(', 'Max(')   # max -> Max\n",
    "    expr = expr.replace('median(', 'Med(') # median -> Med\n",
    "    expr = expr.replace('Median(', 'Med(') # Median -> Med\n",
    "    \n",
    "    # 标准差相关\n",
    "    expr = expr.replace('mstd(', 'Std(')  # mstd -> Std\n",
    "    expr = expr.replace('MSTD(', 'Std(')  # MSTD -> Std\n",
    "    expr = expr.replace('StdDev(', 'Std(') # StdDev -> Std\n",
    "    expr = expr.replace('stddev(', 'Std(') # stddev -> Std\n",
    "    expr = expr.replace('stdev(', 'Std(')  # stdev -> Std\n",
    "    \n",
    "    # 延迟/差分相关\n",
    "    expr = expr.replace('Delay(', 'Ref(')  # Delay -> Ref\n",
    "    expr = expr.replace('Diff(', 'Delta(') # Diff -> Delta\n",
    "    expr = expr.replace('Change(', 'Delta(') # Change -> Delta\n",
    "    \n",
    "    # Pct操作符转换 - Qlib中没有Pct，需要手动实现\n",
    "    # Pct(x, n) = (x - Ref(x, n)) / Ref(x, n)\n",
    "    import re\n",
    "    def replace_pct(match):\n",
    "        field = match.group(1).strip()\n",
    "        window = match.group(2).strip()\n",
    "        return f\"(({field} - Ref({field}, {window})) / Ref({field}, {window}))\"\n",
    "    \n",
    "    expr = re.sub(r'Pct\\(([^,]+),\\s*(\\d+)\\)', replace_pct, expr)\n",
    "    \n",
    "    # Vari操作符转换 - 变异系数\n",
    "    # Vari(x, t) = Std(x, t) / Mean(x, t)\n",
    "    def replace_vari(match):\n",
    "        field = match.group(1).strip()\n",
    "        window = match.group(2).strip()\n",
    "        return f\"(Std({field}, {window}) / Mean({field}, {window}))\"\n",
    "    \n",
    "    expr = re.sub(r'Vari\\(([^,]+),\\s*(\\d+)\\)', replace_vari, expr)\n",
    "    \n",
    "    # Autocorr操作符转换 - 自相关系数\n",
    "    # Autocorr(x, t, n) = Corr(x, Ref(x, n), t)\n",
    "    def replace_autocorr(match):\n",
    "        field = match.group(1).strip()\n",
    "        window = match.group(2).strip()\n",
    "        lag = match.group(3).strip()\n",
    "        return f\"Corr({field}, Ref({field}, {lag}), {window})\"\n",
    "    \n",
    "    expr = re.sub(r'Autocorr\\(([^,]+),\\s*(\\d+),\\s*(\\d+)\\)', replace_autocorr, expr)\n",
    "    \n",
    "    # Zscore操作符转换 - Z分数标准化\n",
    "    # Zscore(x, t) = (x - Mean(x, t)) / Std(x, t)\n",
    "    def replace_zscore(match):\n",
    "        content = match.group(1)\n",
    "        # 找到最后一个逗号的位置（考虑嵌套括号）\n",
    "        depth = 0\n",
    "        last_comma = -1\n",
    "        for i, char in enumerate(content):\n",
    "            if char == '(':\n",
    "                depth += 1\n",
    "            elif char == ')':\n",
    "                depth -= 1\n",
    "            elif char == ',' and depth == 0:\n",
    "                last_comma = i\n",
    "        \n",
    "        if last_comma > 0:\n",
    "            field = content[:last_comma].strip()\n",
    "            window = content[last_comma+1:].strip()\n",
    "            return f\"(({field} - Mean({field}, {window})) / Std({field}, {window}))\"\n",
    "        else:\n",
    "            # 默认窗口20\n",
    "            field = content.strip()\n",
    "            return f\"(({field} - Mean({field}, 20)) / Std({field}, 20))\"\n",
    "    \n",
    "    expr = re.sub(r'Zscore\\(([^)]+)\\)', replace_zscore, expr)\n",
    "    \n",
    "    # 移除或替换三角函数（Qlib不支持）\n",
    "    # Sin(x) -> Sign(x) （简化处理，保持符号信息）\n",
    "    expr = re.sub(r'Sin\\(([^)]+)\\)', r'Sign(\\1)', expr)\n",
    "    # Cos(x) -> 1 （简化处理）\n",
    "    expr = re.sub(r'Cos\\(([^)]+)\\)', '1', expr)\n",
    "    # Tanh(x) -> x / (1 + Abs(x)) （近似处理）\n",
    "    def replace_tanh(match):\n",
    "        content = match.group(1)\n",
    "        return f\"({content} / (1 + Abs({content})))\"\n",
    "    expr = re.sub(r'Tanh\\(([^)]+)\\)', replace_tanh, expr)\n",
    "    \n",
    "    # 修复幂运算符号\n",
    "    expr = re.sub(r'\\^(\\d+)', r'**\\1', expr)  # ^ -> **\n",
    "    expr = re.sub(r'\\^\\s*(\\d+)', r'**\\1', expr)  # ^ -> ** (with spaces)\n",
    "    \n",
    "    # 移除不支持的操作符或替换为支持的\n",
    "    expr = re.sub(r'Normalize\\([^)]+\\)', '1', expr)  # 替换为常数\n",
    "    expr = re.sub(r'Sentiment_Data', '$volume', expr)  # 替换为实际字段\n",
    "    expr = re.sub(r'Econ_Data', '$close', expr)  # 替换为实际字段\n",
    "    expr = re.sub(r'sentiment_index', '$volume', expr)  # 替换为实际字段\n",
    "    expr = re.sub(r'volatility_index', '$close', expr)  # 替换为实际字段\n",
    "    expr = re.sub(r'news_data', '$volume', expr)  # 替换为实际字段\n",
    "    expr = re.sub(r'macro_data', '$close', expr)  # 替换为实际字段\n",
    "    expr = re.sub(r'threshold', '0.5', expr)  # 替换为常数\n",
    "    expr = re.sub(r'AlternativeData', '$volume', expr)  # 替换AlternativeData为volume\n",
    "    \n",
    "    # 移除不支持的函数\n",
    "    expr = re.sub(r'CalculateSentimentScore\\([^)]+\\)', '1', expr)\n",
    "    expr = re.sub(r'SentimentAnalysis\\([^)]+\\)', '1', expr)\n",
    "    expr = re.sub(r'EconomicIndicator\\([^)]+\\)', '1', expr)\n",
    "    expr = re.sub(r'RSI\\([^)]+\\)', 'Mean($close, 14)', expr)  # 简化为均值\n",
    "    expr = re.sub(r'MACD\\([^,)]+,[^,)]+,[^)]+\\)', 'Delta($close, 1)', expr)  # 简化为差分\n",
    "    expr = re.sub(r'Exp\\(', 'Tanh(', expr)  # Exp替换为Tanh\n",
    "    \n",
    "    # 修复语法错误\n",
    "    expr = re.sub(r'\\*\\*0\\.5\\s*Abs', 'Abs', expr)  # 修复**0.5Abs为Abs\n",
    "    expr = re.sub(r'\\*\\*\\s*0\\.5', '**0.5', expr)  # 确保幂运算格式正确\n",
    "    # 修复无效的乘法语法如 **0.5Std\n",
    "    expr = re.sub(r'\\*\\*0\\.5([A-Za-z])', r'0.5*\\1', expr)  # **0.5Std -> 0.5*Std\n",
    "    expr = re.sub(r'\\*\\*0\\.5\\s+([A-Za-z])', r'0.5*\\1', expr)  # **0.5 Std -> 0.5*Std\n",
    "    # 修复exp -> Exp\n",
    "    expr = re.sub(r'\\bexp\\(', 'Tanh(', expr)  # exp不支持，用Tanh替代\n",
    "    \n",
    "    # 移除或简化If操作符（因为参数复杂容易出错）\n",
    "    # 将If(condition, true, false)简化为Sign(condition)\n",
    "    expr = re.sub(r'If\\([^,)]+,[^,)]+,[^)]+\\)', 'Sign($close)', expr)\n",
    "    expr = re.sub(r'If\\([^)]+\\)', 'Sign($close)', expr)\n",
    "    \n",
    "    # 修复不完整的公式 - 尝试补全缺失的括号\n",
    "    open_count = expr.count('(')\n",
    "    close_count = expr.count(')')\n",
    "    if open_count > close_count:\n",
    "        expr += ')' * (open_count - close_count)\n",
    "    \n",
    "    # 清理多余的逗号和空格\n",
    "    expr = re.sub(r',\\s*,', ',', expr)  # 双逗号\n",
    "    expr = re.sub(r',\\s*\\)', ')', expr)  # 逗号后直接闭括号\n",
    "    expr = re.sub(r'\\(\\s*,', '(', expr)  # 开括号后直接逗号\n",
    "    \n",
    "    # 先处理明显的错误模式，如多个字段相加后跟逗号\n",
    "    # 例如: ($open + $close + $high + $low, 5) -> ($open + $close + $high + $low)\n",
    "    # 使用更精确的模式匹配\n",
    "    def fix_multi_field_comma(match):\n",
    "        # 提取括号内的内容\n",
    "        content = match.group(1)\n",
    "        # 如果内容包含多个$字段和运算符，且后面跟着逗号和数字，则移除逗号和数字\n",
    "        if content.count('$') >= 2 and any(op in content for op in ['+', '-', '*', '/']):\n",
    "            # 找到最后一个逗号的位置\n",
    "            parts = content.rsplit(',', 1)\n",
    "            if len(parts) == 2 and parts[1].strip().isdigit():\n",
    "                return f\"({parts[0].strip()})\"\n",
    "        return match.group(0)\n",
    "    \n",
    "    # 需要多次应用来处理嵌套的括号\n",
    "    for _ in range(5):  # 最多处理5层嵌套\n",
    "        prev_expr = expr\n",
    "        expr = re.sub(r'\\(([^()]+)\\)', fix_multi_field_comma, expr)\n",
    "        if expr == prev_expr:  # 没有更多改变，停止\n",
    "            break\n",
    "    \n",
    "    # 使用负向前瞻确保字段有正确的$前缀，避免重复添加\n",
    "    for field in ['open', 'high', 'low', 'close', 'volume', 'turn', 'ret']:\n",
    "        # 只有当字段前面没有$时才添加\n",
    "        expr = re.sub(f'(?<!\\\\$)\\\\b{field}\\\\b', f'${field}', expr)\n",
    "    \n",
    "    # 修复可能已经存在的双美元符号\n",
    "    expr = re.sub(r'\\$\\$(open|high|low|close|volume|turn|ret)\\b', r'$\\1', expr)\n",
    "    \n",
    "    # 处理缺少窗口参数的统计函数\n",
    "    # 使用改进的解析方法处理复杂嵌套\n",
    "    def add_missing_windows(expr):\n",
    "        \"\"\"为统计函数添加缺失的窗口参数\"\"\"\n",
    "        ops_need_window = ['Std', 'Mean', 'Sum', 'Min', 'Max', 'Med', 'Mad', 'Skew', 'Kurt']\n",
    "        result = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(expr):\n",
    "            # 检查是否是需要窗口的操作符\n",
    "            found_op = None\n",
    "            for op in ops_need_window:\n",
    "                if expr[i:].startswith(op + '('):\n",
    "                    found_op = op\n",
    "                    break\n",
    "            \n",
    "            if found_op:\n",
    "                # 找到了操作符\n",
    "                result.append(found_op + '(')\n",
    "                i += len(found_op) + 1\n",
    "                \n",
    "                # 解析参数内容\n",
    "                depth = 1\n",
    "                content_chars = []\n",
    "                comma_at_depth_0 = False\n",
    "                \n",
    "                while i < len(expr) and depth > 0:\n",
    "                    if expr[i] == '(':\n",
    "                        depth += 1\n",
    "                        content_chars.append(expr[i])\n",
    "                    elif expr[i] == ')':\n",
    "                        depth -= 1\n",
    "                        if depth == 0:\n",
    "                            # 到达函数结尾\n",
    "                            content = ''.join(content_chars)\n",
    "                            \n",
    "                            # 检查是否有顶层逗号\n",
    "                            check_depth = 0\n",
    "                            for j, c in enumerate(content):\n",
    "                                if c == '(':\n",
    "                                    check_depth += 1\n",
    "                                elif c == ')':\n",
    "                                    check_depth -= 1\n",
    "                                elif c == ',' and check_depth == 0:\n",
    "                                    comma_at_depth_0 = True\n",
    "                                    break\n",
    "                            \n",
    "                            # 添加内容\n",
    "                            result.append(content)\n",
    "                            \n",
    "                            # 如果没有窗口参数，添加默认值\n",
    "                            if not comma_at_depth_0 and content.strip():\n",
    "                                result.append(', 20')\n",
    "                            \n",
    "                            result.append(')')\n",
    "                        else:\n",
    "                            content_chars.append(expr[i])\n",
    "                    elif expr[i] == ',' and depth == 1:\n",
    "                        comma_at_depth_0 = True\n",
    "                        content_chars.append(expr[i])\n",
    "                    else:\n",
    "                        content_chars.append(expr[i])\n",
    "                    i += 1\n",
    "            else:\n",
    "                # 不是操作符，直接添加字符\n",
    "                result.append(expr[i])\n",
    "                i += 1\n",
    "        \n",
    "        return ''.join(result)\n",
    "    \n",
    "    # 应用多次以处理嵌套情况\n",
    "    for _ in range(5):\n",
    "        prev_expr = expr\n",
    "        expr = add_missing_windows(expr)\n",
    "        if expr == prev_expr:\n",
    "            break\n",
    "    \n",
    "    # 时间序列操作符\n",
    "    expr = re.sub(r'Delta\\(([^,)]+)\\)', r'Delta(\\1, 1)', expr)\n",
    "    expr = re.sub(r'Ref\\(([^,)]+)\\)', r'Ref(\\1, 1)', expr)\n",
    "    expr = re.sub(r'Pct\\(([^,)]+)\\)', r'Pct(\\1, 1)', expr)\n",
    "    \n",
    "    # 注意：Rsquare不是Qlib原生操作符，如果出现则替换为其他操作\n",
    "    expr = expr.replace('Rsquare(', 'Corr(')  # 简单替换为相关系数\n",
    "    \n",
    "    # 处理Rank - 使用智能括号匹配\n",
    "    def add_rank_param(expr):\n",
    "        positions = []\n",
    "        i = 0\n",
    "        while i < len(expr):\n",
    "            if expr[i:].startswith('Rank('):\n",
    "                positions.append(i)\n",
    "            i += 1\n",
    "        \n",
    "        for pos in reversed(positions):\n",
    "            # 找到Rank的开括号位置\n",
    "            start_pos = pos + 5  # 'Rank(' 的长度是5\n",
    "            depth = 0\n",
    "            end_pos = start_pos\n",
    "            \n",
    "            # 找到对应的闭括号\n",
    "            while end_pos < len(expr):\n",
    "                if expr[end_pos] == '(':\n",
    "                    depth += 1\n",
    "                elif expr[end_pos] == ')':\n",
    "                    if depth == 0:\n",
    "                        # 找到了Rank的闭括号\n",
    "                        content = expr[start_pos:end_pos]\n",
    "                        # 检查是否已经有第二个参数\n",
    "                        # 需要更智能的检查，因为内部可能有逗号\n",
    "                        # 计算括号内的逗号（不包括嵌套括号内的）\n",
    "                        comma_count = 0\n",
    "                        paren_depth = 0\n",
    "                        for j, char in enumerate(content):\n",
    "                            if char == '(':\n",
    "                                paren_depth += 1\n",
    "                            elif char == ')':\n",
    "                                paren_depth -= 1\n",
    "                            elif char == ',' and paren_depth == 0:\n",
    "                                comma_count += 1\n",
    "                        \n",
    "                        # 如果没有顶层逗号，说明只有一个参数，需要添加第二个参数\n",
    "                        if comma_count == 0:\n",
    "                            expr = expr[:end_pos] + ', 5' + expr[end_pos:]\n",
    "                        break\n",
    "                    else:\n",
    "                        depth -= 1\n",
    "                end_pos += 1\n",
    "        return expr\n",
    "    \n",
    "    expr = add_rank_param(expr)\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPT调用和两步生成过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可用字段和操作符定义\n",
    "FIELDS = \"$open,$close,$high,$low,$volume,$vwap\"\n",
    "# 注意：只包含Qlib实际支持的操作符\n",
    "OPS = \"Ref,Mean,Std,Sum,Min,Max,Delta,Corr,Cov,Rank,Log,Abs,Sign,Med,Mad,Skew,Kurt\"\n",
    "\n",
    "def gpt_call(prompt: str, temp=0.7):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temp\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "# 维度特定的改进指导\n",
    "DIMENSION_GUIDANCE = {\n",
    "    \"Effectiveness\": {\n",
    "        \"focus\": \"capturing stronger market signals and improving prediction accuracy\",\n",
    "        \"suggestions\": [\n",
    "            \"Incorporate price-volume divergence patterns\",\n",
    "            \"Add momentum or trend-following components\", \n",
    "            \"Capture market microstructure signals\",\n",
    "            \"Include cross-sectional ranking information\"\n",
    "        ]\n",
    "    },\n",
    "    \"Stability\": {\n",
    "        \"focus\": \"reducing noise and improving robustness across different market conditions\",\n",
    "        \"suggestions\": [\n",
    "            \"Apply smoothing techniques like moving averages\",\n",
    "            \"Use longer lookback windows\",\n",
    "            \"Add normalization or standardization\",\n",
    "            \"Incorporate volatility adjustments\"\n",
    "        ]\n",
    "    },\n",
    "    \"Turnover\": {\n",
    "        \"focus\": \"reducing trading frequency while maintaining signal quality\",\n",
    "        \"suggestions\": [\n",
    "            \"Use slower-moving indicators\",\n",
    "            \"Apply signal filtering or thresholding\",\n",
    "            \"Increase holding periods\",\n",
    "            \"Smooth out short-term fluctuations\"\n",
    "        ]\n",
    "    },\n",
    "    \"Diversity\": {\n",
    "        \"focus\": \"exploring unique market phenomena different from existing factors\",\n",
    "        \"suggestions\": [\n",
    "            \"Combine uncorrelated market features\",\n",
    "            \"Use non-linear transformations\",\n",
    "            \"Explore alternative data relationships\",\n",
    "            \"Apply unique mathematical operations\"\n",
    "        ]\n",
    "    },\n",
    "    \"Overfitting\": {\n",
    "        \"focus\": \"simplifying the formula and improving generalization\",\n",
    "        \"suggestions\": [\n",
    "            \"Reduce the number of parameters\",\n",
    "            \"Use more universal patterns\",\n",
    "            \"Avoid overly complex nested operations\",\n",
    "            \"Focus on economically meaningful relationships\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alpha_portrait(context=\"initial\", dimension=None, parent_formula=None, avoid_patterns=None):\n",
    "    \"\"\"第一步：生成Alpha Portrait（基于论文附录J.1）\"\"\"\n",
    "    avoid_txt = f\"\\n\\n设计Alpha表达式时，尽量避免出现如下子表达式：\\n{', '.join(avoid_patterns) if avoid_patterns else '无'}\"\n",
    "    \n",
    "    if context == \"initial\":\n",
    "        prompt = f\"\"\"任务描述：\n",
    "你是一位专注于因子投资的量化金融专家。请根据以下要求，设计一个可用于投资策略的Alpha因子，并以指定格式输出Alpha的内容。\n",
    "\n",
    "可用数据字段：\n",
    "{FIELDS}\n",
    "\n",
    "可用算子：\n",
    "{OPS}\n",
    "\n",
    "Alpha设计要求：\n",
    "1. Alpha值应为无量纲（无单位）。\n",
    "2. Alpha公式需至少包含可用算子中两种不同的操作，确保复杂性，避免过于简单。\n",
    "3. 所有回溯窗口和数值参数必须作为具名参数体现在伪代码中，并遵循Python命名规范（如：lookback_period, volatility_window）。\n",
    "4. Alpha中参数总数不得超过3个。\n",
    "5. 伪代码应分步体现Alpha的计算过程，每行仅使用可用算子及已定义参数。\n",
    "6. 伪代码中使用具描述性的变量名。{avoid_txt}\n",
    "\n",
    "格式要求：\n",
    "输出内容需为JSON格式，包含以下三组键值对：\n",
    "1. \"name\": Alpha名称，需为简洁的变量命名（如 price_volatility_ratio）。\n",
    "2. \"description\": 简明解释该Alpha的用途或意义，强调因子背后的直观动机。\n",
    "3. \"pseudo_code\": 字符串列表，每行为一行简化伪代码，描述Alpha计算的某一步。\n",
    "\n",
    "格式示例：\n",
    "{{\n",
    "  \"name\": \"volatility_adjusted_momentum\",\n",
    "  \"description\": \"捕捉价格动量与波动率的关系，当价格上涨伴随低波动时产生更强信号\",\n",
    "  \"pseudo_code\": [\n",
    "    \"price_change = ($close - Ref($close, lookback_period)) / Ref($close, lookback_period)\",\n",
    "    \"volatility = Std($close, volatility_window)\",\n",
    "    \"signal = price_change / volatility\",\n",
    "    \"alpha = Rank(signal, rank_window)\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "注意：不要使用Pct操作符，改用 (x - Ref(x, n)) / Ref(x, n) 表示百分比变化。\"\"\"\n",
    "    else:\n",
    "        # Refinement context（基于附录J.4）\n",
    "        guidance = DIMENSION_GUIDANCE.get(dimension, {})\n",
    "        prompt = f\"\"\"任务描述：\n",
    "有一个用于量化投资预测资产价格趋势的Alpha因子。请根据下列细化建议，对其进行改进，并输出优化后的Alpha表达式。\n",
    "\n",
    "可用数据字段：\n",
    "{FIELDS}\n",
    "\n",
    "可用算子：\n",
    "{OPS}\n",
    "\n",
    "原始alpha表达式：\n",
    "{parent_formula}\n",
    "\n",
    "细化维度：{dimension}\n",
    "细化重点：{guidance.get('focus', '')}\n",
    "\n",
    "细化建议（注意：下列细化建议无需全部采纳，只需择优、合理采纳部分即可）：\n",
    "{chr(10).join(f'- {s}' for s in guidance.get('suggestions', []))}\n",
    "\n",
    "Alpha建议：\n",
    "1. Alpha值应为无量纲（无单位）。\n",
    "2. 参数总数不得超过3个。\n",
    "3. 伪代码应分步体现Alpha的计算过程。\n",
    "4. 改进应明确针对{dimension}维度。{avoid_txt}\n",
    "\n",
    "格式要求：\n",
    "输出需为JSON格式，包含以下三组键值对：\n",
    "1. \"name\": Alpha名称\n",
    "2. \"description\": 简要说明该Alpha如何改进了{dimension}\n",
    "3. \"pseudo_code\": 字符串列表，每行为一行简化伪代码\n",
    "\n",
    "示例格式同上。\"\"\"\n",
    "    \n",
    "    response = gpt_call(prompt, temp=1.0 if context == \"initial\" else 0.9)\n",
    "    \n",
    "    # 解析JSON响应\n",
    "    try:\n",
    "        import json\n",
    "        portrait_data = json.loads(response)\n",
    "        # 格式化为文本\n",
    "        portrait = f\"\"\"### Alpha Factor Portrait\n",
    "\n",
    "**Alpha Name:** {portrait_data.get('name', 'unknown')}\n",
    "\n",
    "**Description:** {portrait_data.get('description', '')}\n",
    "\n",
    "**Formula Logic:**\n",
    "```\n",
    "{chr(10).join(portrait_data.get('pseudo_code', []))}\n",
    "```\"\"\"\n",
    "        return portrait\n",
    "    except:\n",
    "        # 如果解析失败，返回原始响应\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_formula_from_portrait(portrait, avoid_patterns=None):\n",
    "    \"\"\"第二步：从Portrait生成具体公式（基于论文附录J.2）\"\"\"\n",
    "    \n",
    "    # 从portrait中提取伪代码\n",
    "    pseudo_code = \"\"\n",
    "    if \"Formula Logic:\" in portrait:\n",
    "        start_idx = portrait.find(\"```\") + 3\n",
    "        end_idx = portrait.rfind(\"```\")\n",
    "        if start_idx > 2 and end_idx > start_idx:\n",
    "            pseudo_code = portrait[start_idx:end_idx].strip()\n",
    "    \n",
    "    avoid_txt = f\"\\n8. 设计Alpha表达式时，尽量避免出现如下子表达式：\\n   {', '.join(avoid_patterns) if avoid_patterns else '无'}\"\n",
    "    \n",
    "    prompt = f\"\"\"任务描述：\n",
    "请根据以下要求，设计一个量化投资用的Alpha表达式。\n",
    "\n",
    "可用数据字段：\n",
    "{FIELDS}\n",
    "\n",
    "可用算子：\n",
    "{OPS}\n",
    "\n",
    "Alpha设计要求：\n",
    "基于以下Alpha Portrait生成对应的数学表达式：\n",
    "{portrait}\n",
    "\n",
    "格式要求：\n",
    "请直接输出最终的数学表达式，不要包含JSON格式，不要包含任何解释或其他文字。\n",
    "\n",
    "基于以下伪代码：\n",
    "{pseudo_code}\n",
    "\n",
    "将伪代码转换为具体的数学表达式，使用以下规则：\n",
    "1. 所有参数使用具体数值（在3-60范围内）\n",
    "2. 所有字段必须带$符号（$close, $open等）\n",
    "3. 使用Mean而不是Ma、MA或Moving_Average\n",
    "4. 使用**进行幂运算，不要使用^\n",
    "5. 不要使用If、Zscore、Rsquare、Pct、Vari、Autocorr、Sin、Cos、Tanh等未注册的算子\n",
    "6. 替换规则：\n",
    "   - 百分比变化：Pct(x, n) → (x - Ref(x, n)) / Ref(x, n)\n",
    "   - 变异系数：Vari(x, t) → Std(x, t) / Mean(x, t)\n",
    "   - 自相关：Autocorr(x, t, n) → Corr(x, Ref(x, n), t)\n",
    "   - Z分数：Zscore(x, t) → (x - Mean(x, t)) / Std(x, t)\n",
    "   - 三角函数：不支持Sin、Cos、Tanh，请使用其他数学变换\n",
    "7. 确保函数参数正确，如Std($close, 30)而不是Std(($close, 30))\n",
    "8. 算子名称必须与可用算子列表完全一致{avoid_txt}\n",
    "\n",
    "示例输出（只输出公式，不要其他内容）：\n",
    "Rank((($close - Ref($close, 20)) / Ref($close, 20)) / Std($close, 30), 10)\"\"\"\n",
    "    \n",
    "    response = gpt_call(prompt, temp=0.7)\n",
    "    print(f\"\\nGPT原始响应: {response[:200]}...\")  # 调试信息\n",
    "    \n",
    "    # 直接使用响应作为公式（因为我们已经要求GPT只返回公式）\n",
    "    formula = response.strip()\n",
    "    \n",
    "    # 如果响应仍然包含额外格式，尝试清理\n",
    "    if formula.startswith('```'):\n",
    "        # 去除代码块标记\n",
    "        lines = formula.split('\\n')\n",
    "        formula = '\\n'.join([line for line in lines if not line.startswith('```')])\n",
    "        formula = formula.strip()\n",
    "    \n",
    "    # 清理和修复公式\n",
    "    cleaned_formula = sanitize_formula(formula)\n",
    "    final_formula = fix_missing_params(cleaned_formula)\n",
    "    \n",
    "    print(f\"最终公式: {final_formula}\")  # 调试信息\n",
    "    return final_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_formula(formula):\n",
    "    \"\"\"验证公式是否有效\"\"\"\n",
    "    # 检查是否包含无效操作符（这些会被自动转换）\n",
    "    invalid_ops = ['Moving_Average', 'MovingAverage', 'StdDev', 'Zscore', 'If', 'Exp', \n",
    "                   'RSI', 'MACD', 'AlternativeData', 'threshold', 'sentiment_index', \n",
    "                   'Pct', 'Vari', 'Autocorr', 'Sin', 'Cos', 'Tanh']\n",
    "    for op in invalid_ops:\n",
    "        if op in formula:\n",
    "            return False, f\"Invalid operator: {op}\"\n",
    "    \n",
    "    # 检查是否包含比较运算符\n",
    "    if any(op in formula for op in ['<', '>', '==', '!=', '>=', '<=']):\n",
    "        return False, \"Comparison operators not supported\"\n",
    "    \n",
    "    # 检查是否包含无效字段引用\n",
    "    if 'Number of' in formula or 'Total Stocks' in formula:\n",
    "        return False, \"Invalid market structure references\"\n",
    "    \n",
    "    # 检查括号匹配\n",
    "    if formula.count('(') != formula.count(')'):\n",
    "        return False, \"Unmatched parentheses\"\n",
    "    \n",
    "    # 检查是否有双美元符号\n",
    "    if '$$' in formula:\n",
    "        return False, \"Double dollar signs detected\"\n",
    "    \n",
    "    return True, None\n",
    "\n",
    "def generate_initial():\n",
    "    \"\"\"生成初始Alpha公式（两步过程）\"\"\"\n",
    "    max_attempts = 3\n",
    "    for attempt in range(max_attempts):\n",
    "        portrait = generate_alpha_portrait(\"initial\")\n",
    "        print(f\"\\n生成的Portrait:\\n{portrait}\")  # 调试信息\n",
    "        \n",
    "        formula = generate_formula_from_portrait(portrait)\n",
    "        print(f\"生成的公式: {formula}\")  # 调试信息\n",
    "        \n",
    "        # 如果公式为空或无效，跳过验证\n",
    "        if not formula or formula.startswith('json'):\n",
    "            print(f\"公式生成失败 (尝试 {attempt+1}/{max_attempts}): 返回了JSON而非公式\")\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(\"重新生成...\")\n",
    "                continue\n",
    "        \n",
    "        # 验证公式\n",
    "        is_valid, error_msg = validate_formula(formula)\n",
    "        if is_valid:\n",
    "            return formula, portrait\n",
    "        else:\n",
    "            print(f\"公式验证失败 (尝试 {attempt+1}/{max_attempts}): {error_msg}\")\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(\"重新生成...\")\n",
    "    \n",
    "    # 如果所有尝试都失败，返回一个简单的默认公式\n",
    "    print(\"使用默认公式\")\n",
    "    default_formula = \"Rank(Delta($close, 1) / Std($close, 10), 5)\"\n",
    "    default_portrait = \"### Default Alpha\\n\\nSimple momentum factor\"\n",
    "    return default_formula, default_portrait\n",
    "\n",
    "def refine_formula_advanced(node, dimension, avoid_patterns, repo_examples=None):\n",
    "    \"\"\"高级refinement函数，包含上下文和few-shot示例\"\"\"\n",
    "    # 构建refinement上下文\n",
    "    context = {\n",
    "        'current_formula': node.formula,\n",
    "        'current_scores': node.scores,\n",
    "        'refinement_history': node.refinement_history,\n",
    "        'siblings': [child.formula for child in node.parent.children] if node.parent else []\n",
    "    }\n",
    "    \n",
    "    max_attempts = 3\n",
    "    for attempt in range(max_attempts):\n",
    "        # 生成改进的Alpha Portrait，传递avoid_patterns\n",
    "        portrait = generate_alpha_portrait(\"refinement\", dimension, node.formula, avoid_patterns)\n",
    "        \n",
    "        # 从Portrait生成公式\n",
    "        new_formula = generate_formula_from_portrait(portrait, avoid_patterns)\n",
    "        \n",
    "        # 验证公式\n",
    "        is_valid, error_msg = validate_formula(new_formula)\n",
    "        if is_valid:\n",
    "            # 提取refinement描述\n",
    "            desc_match = re.search(r'\\*\\*Description:\\*\\* (.+?)(?:\\n|$)', portrait)\n",
    "            if not desc_match:\n",
    "                desc_match = re.search(r'Description: (.+?)(?:\\n|$)', portrait)\n",
    "            refinement_desc = desc_match.group(1) if desc_match else f\"Refined for {dimension}\"\n",
    "            \n",
    "            return new_formula, portrait, refinement_desc\n",
    "        else:\n",
    "            print(f\"Refinement公式验证失败 (尝试 {attempt+1}/{max_attempts}): {error_msg}\")\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(\"重新生成refinement...\")\n",
    "    \n",
    "    # 如果所有尝试都失败，返回原公式的简单变体\n",
    "    print(\"使用简单refinement\")\n",
    "    if dimension == \"Stability\":\n",
    "        new_formula = f\"Mean({node.formula}, 20)\"\n",
    "    elif dimension == \"Turnover\":\n",
    "        new_formula = f\"Mean({node.formula}, 30)\"\n",
    "    elif dimension == \"Diversity\":\n",
    "        new_formula = f\"Rank({node.formula}, 10) * Sign(Delta($volume, 5))\"\n",
    "    else:\n",
    "        new_formula = f\"Rank({node.formula}, 5)\"\n",
    "    \n",
    "    return new_formula, f\"Simple refinement for {dimension}\", f\"Applied simple {dimension} improvement\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 简化的评估系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_formula_simple(formula: str, repo_returns: list):\n",
    "    \"\"\"简化的公式评估函数\"\"\"\n",
    "    try:\n",
    "        # 解析公式获取因子数据\n",
    "        factor_expr = formula\n",
    "        \n",
    "        # 计算因子值\n",
    "        try:\n",
    "            factor_data = D.features([\"SH600000\", \"SH600016\", \"SH600036\"], \n",
    "                                   [factor_expr], \n",
    "                                   start_time=start_date, \n",
    "                                   end_time=end_date,\n",
    "                                   freq=\"day\")\n",
    "            \n",
    "            if factor_data.empty:\n",
    "                print(f\"空数据: {formula}\")\n",
    "                return None, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"计算失败: {formula}, 错误: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "        # 模拟评分（基于公式复杂度和结构）\n",
    "        # Effectiveness: 基于操作符多样性\n",
    "        ops_count = len(re.findall(r'[A-Z][a-z]+', formula))\n",
    "        effectiveness = min(10, 2 + ops_count * 1.5 + random.uniform(-1, 2))\n",
    "        \n",
    "        # Stability: 基于窗口长度\n",
    "        windows = [int(x) for x in re.findall(r', (\\d+)', formula)]\n",
    "        avg_window = np.mean(windows) if windows else 5\n",
    "        stability = min(10, 3 + avg_window * 0.3 + random.uniform(-1, 1))\n",
    "        \n",
    "        # Turnover: 反向与窗口长度相关\n",
    "        turnover = max(0, min(10, 8 - avg_window * 0.2 + random.uniform(-1, 1)))\n",
    "        \n",
    "        # Diversity: 基于与现有公式的差异\n",
    "        diversity = 5 + random.uniform(-2, 3)\n",
    "        if repo_returns:\n",
    "            # 模拟相关性检查\n",
    "            max_similarity = 0\n",
    "            for existing in repo_returns:\n",
    "                # 简单的结构相似度\n",
    "                common_ops = len(set(re.findall(r'[A-Z][a-z]+', formula)) & \n",
    "                                set(re.findall(r'[A-Z][a-z]+', existing.get('formula', ''))))\n",
    "                similarity = common_ops / max(ops_count, 1)\n",
    "                max_similarity = max(max_similarity, similarity)\n",
    "            diversity = max(0, min(10, 8 - max_similarity * 5))\n",
    "        \n",
    "        # Overfitting: 基于复杂度\n",
    "        complexity = formula.count('(') + len(windows)\n",
    "        overfitting = max(0, min(10, 9 - complexity * 0.5 + random.uniform(-1, 1)))\n",
    "        \n",
    "        scores = {\n",
    "            \"Effectiveness\": effectiveness,\n",
    "            \"Stability\": stability,\n",
    "            \"Turnover\": turnover,\n",
    "            \"Diversity\": diversity,\n",
    "            \"Overfitting\": overfitting\n",
    "        }\n",
    "        \n",
    "        # 模拟因子收益\n",
    "        factor_returns = pd.Series(np.random.randn(252) * 0.001, \n",
    "                                 index=pd.date_range(start_date, periods=252))\n",
    "        \n",
    "        return scores, {'formula': formula, 'returns': factor_returns}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"评估错误: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AST 解析和频繁子树挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_formula_to_ast(expr: str):\n",
    "    \"\"\"将公式解析为AST树结构\"\"\"\n",
    "    # 将Qlib表达式转换为Python可解析的格式\n",
    "    expr_py = expr.replace('$', 'field_')\n",
    "    expr_py = re.sub(r'([A-Z][a-z]+)', r'func_\\1', expr_py)\n",
    "    \n",
    "    try:\n",
    "        tree = ast.parse(expr_py, mode='eval')\n",
    "        return tree, expr_py\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def extract_subtrees(node, min_size=2):\n",
    "    \"\"\"递归提取所有子树\"\"\"\n",
    "    subtrees = []\n",
    "    \n",
    "    def get_subtree_str(n):\n",
    "        \"\"\"将AST节点转换回字符串表示\"\"\"\n",
    "        if isinstance(n, ast.Name):\n",
    "            return n.id\n",
    "        elif isinstance(n, ast.Constant):\n",
    "            return str(n.value)\n",
    "        elif isinstance(n, ast.Call):\n",
    "            func_name = n.func.id if isinstance(n.func, ast.Name) else str(n.func)\n",
    "            args = [get_subtree_str(arg) for arg in n.args]\n",
    "            return f\"{func_name}({','.join(args)})\"\n",
    "        elif isinstance(n, ast.BinOp):\n",
    "            left = get_subtree_str(n.left)\n",
    "            right = get_subtree_str(n.right)\n",
    "            op = type(n.op).__name__\n",
    "            return f\"({left} {op} {right})\"\n",
    "        return \"?\"\n",
    "    \n",
    "    def count_nodes(n):\n",
    "        \"\"\"计算子树节点数\"\"\"\n",
    "        if isinstance(n, (ast.Name, ast.Constant)):\n",
    "            return 1\n",
    "        elif isinstance(n, ast.Call):\n",
    "            return 1 + sum(count_nodes(arg) for arg in n.args)\n",
    "        elif isinstance(n, ast.BinOp):\n",
    "            return 1 + count_nodes(n.left) + count_nodes(n.right)\n",
    "        elif isinstance(n, ast.Expression):\n",
    "            return count_nodes(n.body)\n",
    "        return 1\n",
    "    \n",
    "    def extract_from_node(n):\n",
    "        if count_nodes(n) >= min_size:\n",
    "            subtrees.append(get_subtree_str(n))\n",
    "        \n",
    "        # 递归处理子节点\n",
    "        if isinstance(n, ast.Call):\n",
    "            for arg in n.args:\n",
    "                extract_from_node(arg)\n",
    "        elif isinstance(n, ast.BinOp):\n",
    "            extract_from_node(n.left)\n",
    "            extract_from_node(n.right)\n",
    "        elif isinstance(n, ast.Expression):\n",
    "            extract_from_node(n.body)\n",
    "    \n",
    "    if node:\n",
    "        extract_from_node(node)\n",
    "    return subtrees\n",
    "\n",
    "class FrequentSubtreeMiner:\n",
    "    def __init__(self, min_support=3):\n",
    "        self.min_support = min_support\n",
    "        self.pattern_counts = defaultdict(int)\n",
    "        self.closed_patterns = set()\n",
    "        \n",
    "    def add_formula(self, formula):\n",
    "        \"\"\"添加新公式并更新模式计数\"\"\"\n",
    "        tree, _ = parse_formula_to_ast(formula)\n",
    "        if tree is None:\n",
    "            return\n",
    "            \n",
    "        subtrees = extract_subtrees(tree)\n",
    "        unique_subtrees = set(subtrees)\n",
    "        \n",
    "        for pattern in unique_subtrees:\n",
    "            self.pattern_counts[pattern] += 1\n",
    "            \n",
    "    def get_frequent_patterns(self):\n",
    "        \"\"\"获取频繁模式\"\"\"\n",
    "        frequent = {p: c for p, c in self.pattern_counts.items() \n",
    "                   if c >= self.min_support}\n",
    "        \n",
    "        # 找出闭合模式（没有更大的超集具有相同支持度）\n",
    "        closed = []\n",
    "        for p1, c1 in frequent.items():\n",
    "            is_closed = True\n",
    "            for p2, c2 in frequent.items():\n",
    "                if p1 != p2 and p1 in p2 and c1 == c2:\n",
    "                    is_closed = False\n",
    "                    break\n",
    "            if is_closed:\n",
    "                closed.append(p1)\n",
    "                \n",
    "        return sorted(closed, key=lambda x: self.pattern_counts[x], reverse=True)\n",
    "    \n",
    "    def should_avoid(self, limit=5):\n",
    "        \"\"\"返回应避免的模式列表\"\"\"\n",
    "        patterns = self.get_frequent_patterns()\n",
    "        return patterns[:limit]\n",
    "\n",
    "# 全局FSA实例\n",
    "fsa_miner = FrequentSubtreeMiner(min_support=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 完整MCTS搜索实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSSearch:\n",
    "    def __init__(self, max_iterations=100, exploration_constant=1.0, \n",
    "                 max_depth=10, max_nodes=1000, checkpoint_freq=10,\n",
    "                 dimension_temperature=1.0):\n",
    "        self.max_iterations = max_iterations\n",
    "        self.exploration_constant = exploration_constant\n",
    "        self.max_depth = max_depth\n",
    "        self.max_nodes = max_nodes\n",
    "        self.checkpoint_freq = checkpoint_freq\n",
    "        self.dimension_temperature = dimension_temperature\n",
    "        self.iteration = 0\n",
    "        self.root = None\n",
    "        self.best_formula = None\n",
    "        self.best_score = -1\n",
    "        self.alpha_repository = []\n",
    "        self.repo_returns = []\n",
    "        self.no_improve_count = 0\n",
    "        \n",
    "    def select_node(self, node):\n",
    "        \"\"\"选择：从根节点开始，使用UCT选择最优路径直到叶节点\"\"\"\n",
    "        path = []\n",
    "        while not node.is_leaf():\n",
    "            if node.is_expandable():\n",
    "                # 如果节点可扩展，返回它进行扩展\n",
    "                return node, path\n",
    "            else:\n",
    "                # 选择UCT值最高的子节点\n",
    "                node = node.best_child(self.exploration_constant)\n",
    "                path.append(node)\n",
    "        return node, path\n",
    "    \n",
    "    def select_dimension(self, node, temperature=1.0):\n",
    "        \"\"\"使用Softmax选择要改进的维度\n",
    "        \n",
    "        根据论文公式: P_dim(d) ← Softmax((e_max*1_q - E_s)/T)\n",
    "        其中:\n",
    "        - e_max = 10 (最大可能得分)\n",
    "        - 1_q 是指示向量，对于维度q为1，其他为0\n",
    "        - E_s 是当前节点的得分向量\n",
    "        - T 是温度参数\n",
    "        \n",
    "        实际含义：维度得分越低，选择概率越高\n",
    "        \"\"\"\n",
    "        scores = node.scores\n",
    "        dims = list(scores.keys())\n",
    "        values = np.array([scores[d] for d in dims])\n",
    "        \n",
    "        # 过滤掉已达到扩展上限的维度\n",
    "        available_dims = []\n",
    "        available_indices = []\n",
    "        for i, dim in enumerate(dims):\n",
    "            if node.expansions_per_dim[dim] < 2:  # 只考虑还能扩展的维度\n",
    "                available_dims.append(dim)\n",
    "                available_indices.append(i)\n",
    "        \n",
    "        if not available_dims:\n",
    "            return None  # 所有维度都达到上限\n",
    "        \n",
    "        # 根据论文公式计算选择概率\n",
    "        e_max = 10.0\n",
    "        available_values = values[available_indices]\n",
    "        \n",
    "        # 对每个可用维度d，计算 (e_max - E_s[d]) / T\n",
    "        # 这相当于计算改进潜力，得分越低，潜力越大\n",
    "        potentials = (e_max - available_values) / temperature\n",
    "        \n",
    "        # Softmax\n",
    "        exp_potentials = np.exp(potentials)\n",
    "        probs = exp_potentials / exp_potentials.sum()\n",
    "        \n",
    "        # 打印选择概率（用于调试）\n",
    "        print(f\"\\n维度选择概率 (论文公式: P_dim(d) = Softmax((e_max - E_s[d])/T)):\")\n",
    "        for d, p, v in zip(available_dims, probs, available_values):\n",
    "            print(f\"  {d}: {p:.3f} (score: {v:.2f}, potential: {e_max-v:.2f}, expansions: {node.expansions_per_dim[d]})\")\n",
    "        \n",
    "        # 选择维度\n",
    "        selected_dim = np.random.choice(available_dims, p=probs)\n",
    "        return selected_dim\n",
    "    \n",
    "    def expand_node(self, node):\n",
    "        \"\"\"扩展：在选中的节点上生成新的子节点\"\"\"\n",
    "        if not node.scores:\n",
    "            # 如果是根节点或未评估的节点，先评估\n",
    "            scores, returns = eval_formula_simple(node.formula, self.repo_returns)\n",
    "            if not scores:\n",
    "                return None\n",
    "            node.scores = scores\n",
    "            node.factor_returns = returns\n",
    "        \n",
    "        # 选择要改进的维度\n",
    "        selected_dim = self.select_dimension(node, temperature=self.dimension_temperature)\n",
    "        if selected_dim is None:\n",
    "            print(\"所有维度都已达到扩展上限\")\n",
    "            return None\n",
    "        print(f\"\\n选择改进维度: {selected_dim}\")\n",
    "        \n",
    "        # 使用高级refinement函数生成改进的公式\n",
    "        avoid_patterns = fsa_miner.should_avoid()\n",
    "        new_formula, portrait, refinement_desc = refine_formula_advanced(\n",
    "            node, selected_dim, avoid_patterns, self.alpha_repository\n",
    "        )\n",
    "        \n",
    "        print(f\"生成新公式: {new_formula}\")\n",
    "        print(f\"改进描述: {refinement_desc}\")\n",
    "        \n",
    "        # 评估新公式\n",
    "        new_scores, new_returns = eval_formula_simple(new_formula, self.repo_returns)\n",
    "        if not new_scores:\n",
    "            return None\n",
    "        \n",
    "        # 创建新节点\n",
    "        child = node.expand(selected_dim, new_formula, new_scores, new_returns, \n",
    "                          portrait, refinement_desc)\n",
    "        \n",
    "        # 更新FSA\n",
    "        fsa_miner.add_formula(new_formula)\n",
    "        \n",
    "        return child\n",
    "    \n",
    "    def simulate(self, node):\n",
    "        \"\"\"模拟：评估节点的价值\"\"\"\n",
    "        if node.scores:\n",
    "            # 计算综合得分\n",
    "            overall_score = np.mean(list(node.scores.values()))\n",
    "            \n",
    "            # 检查是否满足有效性条件\n",
    "            if (node.scores[\"Effectiveness\"] >= 3.0 and \n",
    "                node.scores[\"Diversity\"] >= 2.0 and\n",
    "                overall_score >= 5.0):\n",
    "                # 有效的Alpha，加入仓库\n",
    "                self.alpha_repository.append({\n",
    "                    'formula': node.formula,\n",
    "                    'scores': node.scores,\n",
    "                    'portrait': node.alpha_portrait,\n",
    "                    'refinement_history': node.refinement_history\n",
    "                })\n",
    "                self.repo_returns.append(node.factor_returns)\n",
    "                \n",
    "                # 维护仓库大小\n",
    "                if len(self.alpha_repository) > 20:\n",
    "                    # 删除评分最低的\n",
    "                    scores = [np.mean(list(a['scores'].values())) \n",
    "                             for a in self.alpha_repository]\n",
    "                    min_idx = np.argmin(scores)\n",
    "                    self.alpha_repository.pop(min_idx)\n",
    "                    self.repo_returns.pop(min_idx)\n",
    "                \n",
    "                return overall_score\n",
    "            else:\n",
    "                # 无效的Alpha，返回较低分数\n",
    "                return overall_score * 0.5\n",
    "        return 0\n",
    "    \n",
    "    def backpropagate(self, node, value):\n",
    "        \"\"\"反向传播：更新路径上所有节点的统计信息\"\"\"\n",
    "        node.backpropagate(value)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"运行MCTS搜索\"\"\"\n",
    "        # 初始化根节点\n",
    "        initial_formula, initial_portrait = generate_initial()\n",
    "        self.root = MCTSNode(initial_formula)\n",
    "        self.root.alpha_portrait = initial_portrait\n",
    "        \n",
    "        print(f\"[MCTS] 开始搜索\")\n",
    "        print(f\"初始公式: {initial_formula}\")\n",
    "        print(f\"初始Portrait:\\n{initial_portrait}\\n\")\n",
    "        \n",
    "        for i in range(self.max_iterations):\n",
    "            self.iteration = i\n",
    "            \n",
    "            # 1. 选择\n",
    "            selected_node, path = self.select_node(self.root)\n",
    "            \n",
    "            # 2. 扩展\n",
    "            if selected_node.is_expandable() and len(path) < self.max_depth:\n",
    "                new_node = self.expand_node(selected_node)\n",
    "                if new_node:\n",
    "                    selected_node = new_node\n",
    "            \n",
    "            # 3. 模拟\n",
    "            value = self.simulate(selected_node)\n",
    "            \n",
    "            # 4. 反向传播\n",
    "            self.backpropagate(selected_node, value)\n",
    "            \n",
    "            # 更新最佳结果\n",
    "            if value > self.best_score:\n",
    "                self.best_score = value\n",
    "                self.best_formula = selected_node.formula\n",
    "                self.no_improve_count = 0\n",
    "                print(f\"\\n[{i:03d}] 新最佳! Score={value:.3f}\")\n",
    "                print(f\"Formula: {self.best_formula}\")\n",
    "                print(f\"Scores: {selected_node.scores}\")\n",
    "            else:\n",
    "                self.no_improve_count += 1\n",
    "            \n",
    "            # 定期输出状态\n",
    "            if i % 10 == 0:\n",
    "                print(f\"\\n[{i:03d}] 节点数={self.count_nodes()}, 仓库大小={len(self.alpha_repository)}, \"\n",
    "                      f\"最佳分数={self.best_score:.3f}\")\n",
    "            \n",
    "            # 检查点保存\n",
    "            if i % self.checkpoint_freq == 0:\n",
    "                self.save_checkpoint()\n",
    "            \n",
    "            # 早停条件\n",
    "            if self.no_improve_count >= 50:\n",
    "                print(f\"\\n[{i:03d}] 早停：50轮无改进\")\n",
    "                break\n",
    "            \n",
    "            # 内存限制检查\n",
    "            if self.count_nodes() > self.max_nodes:\n",
    "                print(f\"\\n[{i:03d}] 达到最大节点数限制\")\n",
    "                break\n",
    "        \n",
    "        # 保存最终结果\n",
    "        self.save_results()\n",
    "        \n",
    "        print(f\"\\n搜索完成!\")\n",
    "        print(f\"最佳公式: {self.best_formula}\")\n",
    "        print(f\"最佳分数: {self.best_score:.3f}\")\n",
    "        print(f\"Alpha仓库大小: {len(self.alpha_repository)}\")\n",
    "        \n",
    "        return self.best_formula, self.alpha_repository\n",
    "    \n",
    "    def count_nodes(self):\n",
    "        \"\"\"统计树中的节点数\"\"\"\n",
    "        def count_recursive(node):\n",
    "            if not node:\n",
    "                return 0\n",
    "            return 1 + sum(count_recursive(child) for child in node.children)\n",
    "        return count_recursive(self.root)\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        \"\"\"保存检查点\"\"\"\n",
    "        checkpoint = {\n",
    "            'iteration': self.iteration,\n",
    "            'root': self.root,\n",
    "            'best_formula': self.best_formula,\n",
    "            'best_score': self.best_score,\n",
    "            'alpha_repository': self.alpha_repository,\n",
    "            'repo_returns': self.repo_returns,\n",
    "            'fsa_miner': fsa_miner\n",
    "        }\n",
    "        \n",
    "        filename = f\"mcts_checkpoint_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(checkpoint, f)\n",
    "        print(f\"检查点已保存: {filename}\")\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"保存最终结果到CSV\"\"\"\n",
    "        results = []\n",
    "        for alpha in self.alpha_repository:\n",
    "            result = {\n",
    "                'formula': alpha['formula'],\n",
    "                **alpha['scores'],\n",
    "                'overall': np.mean(list(alpha['scores'].values())),\n",
    "                'refinement_path': ' -> '.join([h['dimension'] for h in alpha['refinement_history']])\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv('mcts_results_v7.csv', index=False)\n",
    "        print(\"结果已保存到 mcts_results_v7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 环境初始化和主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_environment():\n",
    "    \"\"\"初始化Qlib环境和全局变量\"\"\"\n",
    "    global client, close_df, returns_df, universe\n",
    "    \n",
    "    # 初始化Qlib - 禁用多进程以避免Windows错误\n",
    "    qlib.init(provider_uri=\"G:/workspace/qlib_bin/qlib_bin\", region=\"cn\", \n",
    "              joblib_backend=\"sequential\")  # 使用sequential后端避免多进程\n",
    "    \n",
    "    # 初始化OpenAI客户端\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\", \"YOUR_KEY_HERE\"))\n",
    "    \n",
    "    # 获取股票池\n",
    "    universe = D.instruments(market=\"csi300\")\n",
    "    \n",
    "    # 预载收盘价 & 次日收益\n",
    "    close_df = (D.features(universe, ['$close'], start_time=start_date, end_time=end_date, freq='day')\n",
    "                  .reset_index().pivot(index='datetime', columns='instrument', values='$close'))\n",
    "    returns_df = close_df.shift(-1) / close_df - 1\n",
    "    returns_df = returns_df.iloc[:-1]\n",
    "    \n",
    "    return client, close_df, returns_df, universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 运行主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化环境\n",
    "client, close_df, returns_df, universe = initialize_environment()\n",
    "\n",
    "# 运行MCTS搜索\n",
    "mcts = MCTSSearch(\n",
    "    max_iterations=50,  # 减少迭代次数用于测试\n",
    "    exploration_constant=1.0,\n",
    "    max_depth=5,\n",
    "    max_nodes=100,\n",
    "    checkpoint_freq=10,\n",
    "    dimension_temperature=1.0  # 从配置文件读取，默认1.0\n",
    ")\n",
    "\n",
    "best_formula, alpha_repository = mcts.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化结果\n",
    "if alpha_repository:\n",
    "    print(\"\\n=== Alpha Repository ===\")\n",
    "    for i, alpha in enumerate(alpha_repository[:5]):\n",
    "        print(f\"\\n[Alpha {i+1}]\")\n",
    "        print(f\"Formula: {alpha['formula']}\")\n",
    "        print(f\"Scores: {alpha['scores']}\")\n",
    "        print(f\"Overall: {np.mean(list(alpha['scores'].values())):.2f}\")\n",
    "        if alpha['refinement_history']:\n",
    "            print(f\"Refinement Path:\")\n",
    "            for hist in alpha['refinement_history']:\n",
    "                print(f\"  - {hist['dimension']}: {hist['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 结果分析和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载保存的结果\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 读取CSV结果\n",
    "results_df = pd.read_csv('mcts_results_v7.csv')\n",
    "\n",
    "# 绘制各维度得分分布\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "dimensions = ['Effectiveness', 'Stability', 'Turnover', 'Diversity', 'Overfitting', 'overall']\n",
    "\n",
    "for i, dim in enumerate(dimensions):\n",
    "    ax = axes[i//3, i%3]\n",
    "    results_df[dim].hist(ax=ax, bins=20)\n",
    "    ax.set_title(f'{dim} Distribution')\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 显示最佳Alpha\n",
    "print(\"\\n=== Top 5 Alphas by Overall Score ===\")\n",
    "top_alphas = results_df.nlargest(5, 'overall')\n",
    "for idx, row in top_alphas.iterrows():\n",
    "    print(f\"\\nRank {idx+1}:\")\n",
    "    print(f\"Formula: {row['formula'][:100]}...\")\n",
    "    print(f\"Overall Score: {row['overall']:.2f}\")\n",
    "    print(f\"Scores: E={row['Effectiveness']:.2f}, S={row['Stability']:.2f}, \"\n",
    "          f\"T={row['Turnover']:.2f}, D={row['Diversity']:.2f}, O={row['Overfitting']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}